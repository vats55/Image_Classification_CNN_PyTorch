{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification using CNN - pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libraries \n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim \n",
    "\n",
    "import os \n",
    "import glob \n",
    "import numpy as np \n",
    "from skimage import io \n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "\n",
    "from skimage import transform\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In case you want to pull data from google drive into a google collab environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files, drive \n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network Architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computation will use GPU or CPU. If GPU available, then use or else use CPU \n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class Net(nn.Module): \n",
    "    \n",
    "    def __init__(self): \n",
    "\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        # input -> conv1 -> relu -> pool1 -> conv2 -> relu -> pool2 -> flatten -> FC1 -> relu -> dropout -> FC2\n",
    "\n",
    "        self.conv_1 = nn.Conv2d(1,32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv_2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.max_pool2d = nn.MaxPool2d(kernel_size=2, stride=2) \n",
    "        self.linear_1 = nn.Linear(7 * 7 * 64, 128) # input of 7*7*64 is determined from the output of 2nd pooling layer\n",
    "        self.linear_2 = nn.Linear(128, 10) # the output of 10 has to be correspond \n",
    "        self.dropout = nn.Dropout(p=0.5) #reduce overfitting\n",
    "        self.relu = torch.nn.ReLU() #relu is used as activation to reduce non-linearity\n",
    "\n",
    "    def forward(self,x): \n",
    "        x = self.conv_1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.max_pool2d(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.max_pool2d(x)\n",
    "        x = x.reshape(x.size(0), -1) #flatten \n",
    "        x = self.linear_1(x) \n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        pred = self.linear_2(x)\n",
    "\n",
    "        return F.log_softmax(pred)\n",
    "\n",
    "net = Net().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customized MNIST Dataset loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataset(Dataset): \n",
    "\n",
    "    def __init__(self,dir,transform=None): \n",
    "        self.dir = dir \n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        files = glob.glob(self.dir+'/*.jpg') #[:50]\n",
    "        return len(files)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        \n",
    "        if torch.is_tensor(idx): \n",
    "            idx = idx.tolist()\n",
    "\n",
    "        all_instances = glob.glob(self.dir + '/*.jpg') #[:50] #list of file names \n",
    "        img_fname = os.path.join(self.dir,all_instances[idx]) #path to image instances \n",
    "        image = io.imread(img_fname) #convert to numpy array\n",
    "        digit = int(self.dir.split('/')[-1].strip())\n",
    "        label = np.array(digit)\n",
    "\n",
    "        instance = {'image':image, 'label':label}\n",
    "\n",
    "        if self.transform:\n",
    "            instance = self.transform(instance)\n",
    "\n",
    "        #so what did we get at the end: inside of dataloader, you have batches, each batch will have multiple images, each image will then be a dictionary with two key,value pairs - image with its ndarray and key with its digit value\n",
    "\n",
    "        return instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Transformations of Rescaling and convert to Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 transformation\n",
    "class Rescale(object):\n",
    "    \n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        \n",
    "        image, label = sample['image'], sample['label'] #from dictionary like structure for each image\n",
    "        h, w = image.shape[-2:] \n",
    "\n",
    "        if isinstance(self.output_size, int): \n",
    "            \n",
    "            if h > w:\n",
    "                new_h, new_w = self.output_size*h/w, self.output_size\n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size*w/h\n",
    "\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "        new_image = transform.resize(image, (new_h, new_w)) #apply the new computed heights and width \n",
    "\n",
    "        return {'image': new_image, 'label':label} #this will return images with a consistent height and width throughout\n",
    "\n",
    "#2 transformation\n",
    "class ToTensor(object):\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "        image = image.reshape((1,image.shape[0],image.shape[1])) #convert 2d to 3d\n",
    "        return {'image':torch.from_numpy(image) ,'label': torch.from_numpy(label)} #convert image and label from np array into tensor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training/validation dataset loader\n",
    "batch_size = 10\n",
    "list_datasets = []\n",
    "\n",
    "for i in range(10): # we have images inside of 10 different folder, hence 10\n",
    "    \n",
    "    cur_ds = MNISTDataset('/content/drive/My Drive/trainingset/'+str(i), transform= transforms.Compose([Rescale(28), ToTensor()])) \n",
    "    list_datasets.append(cur_ds)\n",
    "\n",
    "dataset = torch.utils.data.ConcatDataset(list_datasets) #one dataset with all training set instances \n",
    "\n",
    "train_size = int(len(dataset)*0.7)\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset,[train_size, val_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset,batch_size,shuffle=True,num_workers=1) \n",
    "val_dataloader = DataLoader(val_dataset,batch_size,shuffle=True,num_workers=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display one training instance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, batch in enumerate(train_dataloader): \n",
    "    inputs,targets = batch['image'].to(device), batch['label'].to(device)\n",
    "    break\n",
    "\n",
    "plt.imshow(inputs[0].numpy().squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "criterion = nn.CrossEntropyLoss() #since we have multiclass classification\n",
    "\n",
    "#for train/val loss graph\n",
    "train_loss_list=[]\n",
    "val_loss_list=[]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    ############# TRAIN ###############\n",
    "    net.train()\n",
    "    running_loss=0.0\n",
    "\n",
    "    for batch_idx, batch in enumerate(train_dataloader): \n",
    "        inputs,targets = batch['image'].to(device,dtype=torch.float), batch['label'].to(device,dtype=torch.long)\n",
    "\n",
    "    # Training pass\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = net(inputs)\n",
    "        loss = criterion(output, targets)\n",
    "        \n",
    "    #This is where the model learns by backpropagating\n",
    "        loss.backward()\n",
    "        \n",
    "    #And optimizes its weights here\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    train_loss_list.append(running_loss/(batch_idx+1))  \n",
    "    print(\"Epoch {} - Training loss: {}\".format(epoch+1, running_loss/(batch_idx+1)))\n",
    "\n",
    "    \n",
    "    ########### TESTING over validation set #############\n",
    "    net.eval()\n",
    "\n",
    "    correct = [0.0]*10\n",
    "    total = [0.0]*10\n",
    "    val_acc=0.0\n",
    "    val_loss=0.0\n",
    "    final_val_acc=0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for batch_idx, batch in enumerate(val_dataloader): \n",
    "            \n",
    "            inputs,targets = batch['image'].to(device,dtype=torch.float), batch['label'].to(device,dtype=torch.long)\n",
    "            pred_outputs = net(inputs)\n",
    "\n",
    "    \n",
    "            val_loss += F.nll_loss(pred_outputs, targets, size_average=False).item()\n",
    "\n",
    "            _,pred_targets = torch.max(pred_outputs,1)\n",
    "            c=(pred_targets == targets)\n",
    "\n",
    "            for i in range(len(targets)):\n",
    "                target = targets[i]\n",
    "                correct[target] += c[i].item()\n",
    "                total[target] +=1\n",
    "\n",
    "    for i in range(10): \n",
    "        val_acc += 100*correct[i]/total[i]\n",
    "    final_val_acc = val_acc/10\n",
    "    val_loss_list.append(val_loss/(batch_idx+1)) \n",
    "\n",
    "    print(\"Epoch {} - Val Acc: {}\".format(epoch+1, final_val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Validation loss graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(20, 10))\n",
    "plt.plot(np.arange(1, epochs+1), train_loss_list, label=\"Train loss\")\n",
    "plt.plot(np.arange(1, epochs+1), val_loss_list, label=\"Validation loss\")\n",
    "plt.xlabel('Loss')\n",
    "plt.ylabel('Epochs')\n",
    "plt.title(\"Loss Plots\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data + Testing over trained model above (only part where dataset API from torchvision is used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=transforms.Compose([transforms.Resize(28),transforms.ToTensor()]))\n",
    "test_dataloader = torch.utils.data.DataLoader(mnist_testset, batch_size=32, shuffle=False)\n",
    "\n",
    "net.eval()\n",
    "\n",
    "results = list()\n",
    "total = 0\n",
    "for itr, (image, label) in enumerate(test_dataloader):\n",
    "    pred = net(image)\n",
    "    pred = torch.nn.functional.softmax(pred, dim=1)\n",
    "\n",
    "    for i, p in enumerate(pred):\n",
    "        if label[i] == torch.max(p.data, 0)[1]:\n",
    "            total = total + 1\n",
    "            results.append((image, torch.max(p.data, 0)[1]))\n",
    "\n",
    "test_accuracy = total / (itr + 1)\n",
    "print('Test accuracy {:.8f}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
